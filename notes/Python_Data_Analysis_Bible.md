# 游닀 La Biblia del Analista de Datos con Python

## El Credo del Analista

Un Analista de Datos es un **traductor**. Habla el lenguaje de los datos (n칰meros, tablas, estad칤sticas) y lo traduce al lenguaje de las decisiones (estrategia, crecimiento, oportunidad).

### 쯇or Qu칠 Python? 游냀

Python es el idioma universal del an치lisis. Es un **bistur칤 suizo** 游뻟릖:

* Es **legible** y f치cil de escribir, por lo que tu c칩digo se documenta solo.
* Es **poderoso** y se integra con todo (bases de datos, web, IA).
* Tiene un **ecosistema** de librer칤as (`Pandas`, `NumPy`, `Seaborn`) que hacen el 90% del trabajo pesado por ti.

### El Objetivo Final

El objetivo no es crear c칩digo complejo. El objetivo es encontrar la **verdad** oculta en los datos y **comunicarla** de una forma tan clara y convincente que impulse a la acci칩n.

### El Juramento: Las Buenas Pr치cticas

1. **Siempre conocer치s tus datos:** Nunca inicies un an치lisis sin una exploraci칩n previa. Desconf칤a de los datos hasta que hayas probado que son limpios.
2. **Tu c칩digo es para humanos:** Escribir치s c칩digo que otros (y tu "yo" del futuro) puedan entender. Usar치s nombres de variables claros y dejar치s comentarios.
3. **Tu an치lisis ser치 reproducible:** Lo que haces en un *notebook* (`.ipynb`) debe poder ser ejecutado por alguien m치s y dar el mismo resultado.
4. **No sacar치s conclusiones apresuradas:** Siempre visualizar치s tus hallazgos. Un gr치fico puede desmentir una estad칤stica (como la media).

---

## El Ritual: El Flujo de Trabajo del Analista

Este es el proceso paso a paso, desde la pantalla en blanco hasta el *insight* final.

### Paso 0: La Invocaci칩n (Importar Librer칤as)

Todo an치lisis comienza con la misma invocaci칩n. Abres tu Notebook (`.ipynb`) y llamas a tus herramientas.

```python
# --- El "Santo Grial" de las importaciones ---

# 1. Pandas: La herramienta para manipular tablas (DataFrames)
import pandas as pd

# 2. NumPy: El motor matem치tico (lo usa Pandas por debajo)
import numpy as np

# 3. Matplotlib: La base para TODOS los gr치ficos
import matplotlib.pyplot as plt

# 4. Seaborn: La librer칤a para gr치ficos estad칤sticos bonitos
import seaborn as sns

# 5. SQL: Habilitamos el uso de SQL dentros de Pandas
from pandasql import sqldf

# --- Configuraciones de buenas pr치cticas ---
# Configurar SQL
pysqldf = lambda q: sqldf(q, globals())
# Configura Seaborn para que los gr치ficos se vean m치s modernos
sns.set_theme(style="whitegrid")
# (Opcional) Evita que salgan n칰meros en notaci칩n cient칤fica
pd.set_option('display.float_format', lambda x: '%.2f' % x)

print("Librer칤as listas. Taller abierto.")
```

### Paso 1: La Adquisici칩n (Cargar los Datos)

Debes traer el "material en bruto" (tus archivos) a tu taller (el DataFrame de Pandas).

```python
# --- Cargar un archivo CSV (El m치s com칰n) ---
# (Aseg칰rate de que el CSV est칠 en la misma carpeta)
df = pd.read_csv('nombre_del_archivo.csv')

# --- Cargar un archivo Excel ---
# (Puede ser m치s lento que CSV. A veces hay que especificar la hoja)
df = pd.read_excel('nombre_del_archivo.xlsx', sheet_name='Hoja1')
```

### Paso 2: El Vistazo (La Primera Inspecci칩n)

Acabas de recibir una caja. Antes de usar su contenido, la abres y miras qu칠 hay dentro.

```python
# --- 1. Ver las primeras 5 filas ---
# 쯉on los datos lo que esperabas? 쯃os nombres de columna son correctos?
print(df.head())

# --- 2. Ver las 칰ltimas 5 filas ---
# 쮿ay datos basura o sumarios al final del archivo?
print(df.tail())

# --- 3. Obtener la forma (Shape) ---
# 쮺u치ntas filas y columnas tengo?
print(f"Filas: {df.shape[0]}, Columnas: {df.shape[1]}")

# --- 4. La Ficha T칠cnica (LA M츼S IMPORTANTE) ---
# .info() es tu radiograf칤a. Te dice:
# - El nombre de CADA columna.
# - Cu치ntos valores NO NULOS tiene cada una (춰para detectar datos faltantes!).
# - El tipo de dato (Dtype) de cada columna (object=texto, float64=n칰mero).
print(df.info())
```

### Paso 3: La Radiograf칤a (Resumen Estad칤stico)

Ahora que sabes qu칠 hay, veamos c칩mo se comportan los datos.

```python
# --- 1. Resumen Estad칤stico de Columnas NUM칄RICAS ---
# .describe() te da la media, mediana (50%), desviaci칩n est치ndar,
# m칤nimo y m치ximo. Es VITAL para detectar outliers.
print(df.describe())

# --- 2. Resumen de Columnas CATEG칍RICAS (Texto) ---
# 쮺u치ntos valores 칰nicos hay?
print(df['Competition'].nunique()) # Ej: 3 (Low, Medium, High)

# 쮺칩mo se distribuyen? (Contar cu치ntas veces aparece cada valor)
print(df['Competition'].value_counts())
```

### Paso 4: La Limpieza (El 80% del Trabajo)

Rara vez los datos vienen listos para usar. Debes ser un cirujano y arreglarlos.

```python
# --- 4.1. Manejo de Columnas (Renombrar) ---
# Buena pr치ctica: Nombres en min칰scula, sin espacios, todo en ingl칠s.
df_limpio = df.rename(columns={
    'Avg. monthly searches': 'avg_monthly_searches',
    'YoY change': 'yoy_change'
})
# TRUCO PRO: Renombra TODAS las columnas a la vez
df_limpio.columns = [col.lower().replace(' ', '_').replace('(', '').replace(')', '') for col in df_limpio.columns]


# --- 4.2. Manejo de Nulos (Datos Faltantes) ---
# 쮺u치ntos nulos tengo por columna?
print(df_limpio.isnull().sum())

# Opci칩n A: Eliminar filas que tengan nulos en una columna clave
df_limpio = df_limpio.dropna(subset=['avg_monthly_searches'])

# Opci칩n B: Rellenar nulos (Ej: rellenar con la media o un valor espec칤fico)
media_bid = df_limpio['bid_low'].mean()
df_limpio['bid_low'] = df_limpio['bid_low'].fillna(media_bid)


# --- 4.3. Correcci칩n de Tipos de Datos (Dtype) ---
# (Como hicimos con 'yoy_change' que era texto por el '%')
# 1. Limpiar el string
df_limpio['yoy_change'] = df_limpio['yoy_change'].str.replace('%', '')
# 2. Convertir a n칰mero (errors='coerce' es tu salvavidas)
df_limpio['yoy_change'] = pd.to_numeric(df_limpio['yoy_change'], errors='coerce')


# --- 4.4. Manejo de Duplicados ---
# 쮺u치ntas filas est치n exactamente duplicadas?
print(f"Filas duplicadas: {df_limpio.duplicated().sum()}")
# Eliminarlas
df_limpio = df_limpio.drop_duplicates()
```

### Paso 5: La Interrogaci칩n (An치lisis y NumPy)

Ahora que los datos est치n limpios, les hacemos preguntas. Aqu칤 es donde Pandas (el coche) usa el motor de NumPy (los c치lculos).

```python
# --- 5.1. Selecci칩n y Filtrado (El "WHERE" de SQL) ---
# Seleccionar una columna (devuelve una "Serie" de Pandas)
nombres_keywords = df_limpio['keyword']

# Seleccionar m칰ltiples columnas (devuelve un DataFrame)
df_keywords_y_busquedas = df_limpio[['keyword', 'avg_monthly_searches']]

# Filtrar filas (condiciones booleanas)
df_competencia_baja = df_limpio[df_limpio['competition'] == 'Low']

# Filtro multi-condicional (& = "y", | = "o")
df_baja_y_alto_crecimiento = df_limpio[
    (df_limpio['competition'] == 'Low') & 
    (df_limpio['yoy_change'] > 100)
]


# --- 5.2. Creaci칩n de Nuevas Columnas (Feature Engineering) ---
# (Aqu칤 Pandas usa NumPy por debajo para hacer los c치lculos)
df_limpio['busquedas_por_competencia'] = df_limpio['avg_monthly_searches'] / df_limpio['competition_index']

# Usando una funci칩n de NumPy directamente (Ej: logaritmo para normalizar)
df_limpio['log_busquedas'] = np.log(df_limpio['avg_monthly_searches'] + 1) # +1 para evitar log(0)


# --- 5.3. Agregaci칩n (El "GROUP BY" de SQL) ---
# La herramienta M츼S PODEROSA de Pandas.
# Pregunta: 쮺u치l es la media de b칰squedas y crecimiento por nivel de competencia?
df_agrupado = df_limpio.groupby('competition').agg(
    media_busquedas=('avg_monthly_searches', 'mean'),
    mediana_crecimiento=('yoy_change', 'median'),
    cantidad_keywords=('keyword', 'count')
)
# Ordenar el resultado
df_agrupado = df_agrupado.sort_values(by='media_busquedas', ascending=False)
print(df_agrupado)
```

### Paso 6: La Revelaci칩n (Visualizaci칩n con Matplotlib/Seaborn)

Los n칰meros son abstractos. Las im치genes cuentan historias.
El Ritual de Matplotlib: Casi todos los gr치ficos de Seaborn terminan con comandos de Matplotlib (plt) para afinarlos.

```python
# --- El Ritual para CADA GR츼FICO ---
plt.figure(figsize=(10, 6)) # 1. Define el tama침o del lienzo
# (Aqu칤 va el c칩digo de Seaborn)
plt.title('T칤tulo del Gr치fico')
plt.xlabel('Etiqueta del Eje X')
plt.ylabel('Etiqueta del Eje Y')
plt.show() # 4. Muestra el gr치fico
```

#### Pregunta 1: 쮺칩mo se distribuyen mis datos? (Univariado)

Herramienta: Histograma o KDE (Kernel Density Estimate)

```python
# Ver la distribuci칩n de las b칰squedas (춰la que vimos que estaba sesgada!)
plt.figure(figsize=(10, 6))
sns.histplot(data=df_limpio, x='avg_monthly_searches', kde=True, bins=50)
plt.title('Distribuci칩n de B칰squedas Mensuales')
plt.xlabel('B칰squedas Mensuales')
plt.ylabel('Frecuencia (Keywords)')
# (Opcional) Limitar el eje X para ver el detalle
plt.xlim(0, 1000)
plt.show()
```

#### Pregunta 2: 쮿ay relaci칩n entre dos variables? (Bivariado)

Herramienta: Gr치fico de Dispersi칩n (Scatterplot)

```python
# Relaci칩n entre competencia y crecimiento? (El que hicimos)
plt.figure(figsize=(10, 6))
sns.scatterplot(data=df_limpio, x='competition_index', y='yoy_change')
plt.title('Relaci칩n entre Competencia y Crecimiento (YoY)')
plt.xlabel('칈ndice de Competencia')
plt.ylabel('Crecimiento Interanual (%)')
plt.show()
```

#### Pregunta 3: 쮺칩mo se comparan estas categor칤as?

Herramienta: Gr치fico de Barras (Barplot)

```python
# Usamos el DataFrame agrupado que creamos antes
plt.figure(figsize=(10, 6))
# Nota: Para data=df_agrupado, 'x' debe ser una columna, as칤 que reseteamos el 칤ndice
df_agrupado_para_grafico = df_agrupado.reset_index()
sns.barplot(data=df_agrupado_para_grafico, x='competition', y='media_busquedas')
plt.title('Media de B칰squedas por Nivel de Competencia')
plt.xlabel('Nivel de Competencia')
plt.ylabel('Media de B칰squedas')
plt.show()
```

#### Pregunta 4: 쮺칩mo se distribuyen las categor칤as?

Herramienta: Gr치fico de Conteo (Countplot)

```python
# Ver cu치ntas keywords hay de cada nivel de competencia
plt.figure(figsize=(8, 5))
sns.countplot(data=df_limpio, x='competition')
plt.title('Conteo de Keywords por Nivel de Competencia')
plt.xlabel('Nivel de Competencia')
plt.ylabel('Cantidad de Keywords')
plt.show()
```

#### Pregunta 5: 쮺칩mo es la distribuci칩n por categor칤a?

Herramienta: Gr치fico de Cajas (Boxplot) (Este es genial para comparar medianas y detectar outliers por grupo)

```python
# Ver la distribuci칩n de b칰squedas PARA CADA nivel de competencia
plt.figure(figsize=(10, 6))
sns.boxplot(data=df_limpio, x='competition', y='avg_monthly_searches')
plt.title('Distribuci칩n de B칰squedas por Competencia')
plt.xlabel('Nivel de Competencia')
plt.ylabel('B칰squedas Mensuales')
# (Opcional) Limitar el eje Y para que los outliers no aplasten el gr치fico
plt.ylim(0, 2000)
plt.show()
```

### Paso 7: El Arte de Unir (Combinando M칰ltiples Archivos)

Rara vez todos tus datos estar치n en un solo CSV.

#### La herramienta clave es `pd.merge()`

```python
# --- Paso Adicional: Uniendo M칰ltiples Fuentes ---

# Asumimos que tienes dos DataFrames:
# df_pedidos (con columnas 'id_cliente', 'id_producto', 'fecha_compra')
# df_clientes (con columnas 'id_cliente', 'nombre_cliente', 'ciudad')

# Queremos a침adir la 'ciudad' del cliente a nuestra tabla de 'pedidos'.
# Usamos 'id_cliente' como la llave (key) que tienen en com칰n.

df_completo = pd.merge(
    df_pedidos,
    df_clientes[['id_cliente', 'ciudad']], # Solo traemos las columnas que necesitamos
    on='id_cliente',   # La columna que usan para conectarse
    how='left'         # 'how=left' es el tipo de uni칩n (como un LEFT JOIN en SQL)
                       # Mantiene todos los pedidos y a침ade info del cliente si la encuentra.
 )

print(df_completo.head())
```

#### `pd.concat()` (Concatenar)

* **쯈u칠 es?** Es la herramienta para **"pegar" o "apilar"** DataFrames, ya sea uno encima del otro (verticalmente) o uno al lado del otro (horizontalmente).
* **Analog칤a:** Piensa en `pd.concat()` como **pegar hojas de papel**.
  * **Uni칩n Vertical (`axis=0`)**: Tienes dos hojas de asistencia (una de enero, otra de febrero) con las **mismas columnas** (Nombre, DNI, Asistencia). `pd.concat` las pega una debajo of the otra para crear una sola lista m치s larga (enero + febrero).
  * **Uni칩n Horizontal (`axis=1`)**: Tienes una hoja con los *nombres* de los estudiantes y otra hoja con sus *notas*. Ambas tienen el **mismo 칤ndice** (el mismo orden). `pd.concat` las pega una al lado de la otra para crear una tabla m치s ancha.
* **Uso Principal:** Apilar datos que tienen la misma estructura (ej. `ventas_2024.csv` y `ventas_2025.csv`).

```python
# Ejemplo de Concatenaci칩n Vertical (la m치s com칰n)

# Datos de ventas del primer trimestre
df_q1 = pd.DataFrame({
    'id_cliente': ['A', 'B', 'C'],
    'venta': [100, 200, 150]
})

# Datos de ventas del segundo trimestre
df_q2 = pd.DataFrame({
    'id_cliente': ['A', 'D', 'E'],
    'venta': [50, 300, 100]
})

# Concatenamos los dos trimestres para tener un historial completo
# ignore_index=True es importante para crear un nuevo 칤ndice (0, 1, 2, 3, 4, 5)
df_total_a침o = pd.concat([df_q1, df_q2], ignore_index=True)

print(df_total_a침o)
#  id_cliente  venta
#0          A    100
#1          B    200
#2          C    150
#3          A     50
#4          D    300
#5          E    100 
```

#### `df.join()` (Unir por 칈ndice)

* **쯈u칠 es?** Es un atajo de `pd.merge()` que se especializa en unir DataFrames bas치ndose en sus **칤ndices (index)** en lugar de columnas.
* **Analog칤a:** Es un `VLOOKUP` (BUSCARV) de Excel donde la clave de b칰squeda no es una columna, sino el **n칰mero de fila (o la etiqueta del 칤ndice)**.
* **Uso Principal:** Cuando tienes dos tablas donde las filas ya est치n alineadas por un 칤ndice com칰n (ej. `id_cliente`) y quieres a침adir columnas de una a la otra.
* **Diferencia clave con `merge`:** `df1.join(df2)` une el 칤ndice de `df1` con el 칤ndice de `df2` por defecto. `pd.merge()` une columnas de `df1` con columnas de `df2`.

```python
# Ejemplo de Join por 칈ndice

# Datos de clientes, indexados por 'id_cliente'
df_clientes = pd.DataFrame({
    'nombre': ['Ana', 'Juan', 'Elena'],
    'email': ['ana@mail.com', 'juan@mail.com', 'elena@mail.com']
}, index=['c1', 'c2', 'c3'])
df_clientes.index.name = 'id_cliente'

# Datos demogr치ficos, tambi칠n indexados por 'id_cliente'
df_demograficos = pd.DataFrame({
    'edad': [28, 34, 45],
    'ciudad': ['Madrid', 'Lima', 'Bogot치']
}, index=['c1', 'c2', 'c3'])
df_demograficos.index.name = 'id_cliente'

# Usamos .join() para "pegar" las columnas de df_demograficos a df_clientes
# Como ambos tienen el mismo 칤ndice, es autom치tico.
df_perfil_completo = df_clientes.join(df_demograficos)

print(df_perfil_completo)

#            nombre            email  edad  ciudad
#id_cliente
#c1            Ana     ana@mail.com    28  Madrid
#c2           Juan    juan@mail.com    34    Lima
#c3          Elena   elena@mail.com    45  Bogot치
```

**`merge` vs. `join` vs. `concat` (El Resumen)**

* pd.concat(): "Apilar" o "Pegar" (como apilar bloques de LEGO).
* pd.merge(): "Fusionar" (como un JOIN de SQL). Es la m치s potente y flexible. Se basa en columnas con valores comunes (ej. 'id_cliente' en ambas tablas).
* df.join(): "Unir" (como un VLOOKUP). Es un atajo para merge cuando la uni칩n se basa en los 칤ndices (las etiquetas de las filas).

### Paso 8: El Dominio del Tiempo (Manejo de Fechas y Horas)

Los datos de series temporales deben ser tratados de forma especial. La herramienta clave es pd.to_datetime().

```python
# --- Paso Adicional: Manejo de Series de Tiempo ---

# Asumimos que df_completo tiene una columna 'fecha_compra' que es texto
print(df_completo.info()) # Mostrar칤a 'fecha_compra' como 'object'

# 1. Convertir la columna de texto a formato datetime
df_completo['fecha_compra'] = pd.to_datetime(df_completo['fecha_compra'])

# 2. Ahora que es datetime, 춰podemos extraer partes de ella!
df_completo['mes_compra'] = df_completo['fecha_compra'].dt.month
df_completo['a침o_compra'] = df_completo['fecha_compra'].dt.year
df_completo['dia_semana'] = df_completo['fecha_compra'].dt.day_name()

print(df_completo[['fecha_compra', 'mes_compra', 'dia_semana']].head())

# 3. La magia: Establecer la fecha como el 칤ndice para an치lisis de tiempo
df_completo = df_completo.set_index('fecha_compra')

# Ahora puedes hacer cosas como "agrupar por mes" y sumar las ventas
df_ventas_mensuales = df_completo.resample('M')['total_venta'].sum()
print(df_ventas_mensuales)
```

### Paso 9: La Conclusi칩n (Guardar y Comunicar)

Has encontrado la verdad. Ahora, gu치rdala y prepara tu informe.

```python
# --- Guardar tu DataFrame limpio para el futuro ---
# (index=False es VITAL para no guardar el 칤ndice como una columna)
df_limpio.to_csv('datos_google_ads_LIMPIO.csv', index=False)

# --- Guardar tu DataFrame agrupado (tu insight) ---
df_agrupado.to_csv('resumen_por_competencia.csv')

# --- Guardar tus Gr치ficos ---
# (Ejecuta esto en la celda de tu gr치fico, justo ANTES de plt.show())
# plt.savefig('mi_grafico_de_barras.png', dpi=300) # dpi=300 para alta resoluci칩n

print("An치lisis completado. Archivos limpios y de resultados guardados.")
```

### Paso 10: El Informe (La Comunicaci칩n)

El an치lisis no est치 completo hasta que se comunica. En tu notebook, a침ade una celda de Markdown al final y escribe tus conclusiones clave.

#### Reporte Ejecutivo: An치lisis de Keywords de Google Ads

A continuaci칩n, se presentan los hallazgos clave del an치lisis:

* **Oportunidad Identificada:** Se detect칩 una tendencia emergente en la keyword "acceso financiero", con un crecimiento interanual (YoY) del **2000%** y una competencia clasificada como "Baja". Se recomienda la creaci칩n inmediata de contenido para capturar este inter칠s.

* **Distribuci칩n de B칰squedas:** La gran mayor칤a de las keywords (mediana = 10 b칰squedas) tienen un volumen bajo. La media (113 b칰squedas) est치 fuertemente sesgada por unas pocas keywords de alto rendimiento.

* **Competencia vs. Crecimiento:** No se encontr칩 una correlaci칩n clara entre el nivel de competencia de una keyword y su crecimiento interanual. Esto sugiere que las keywords de alta competencia no crecen necesariamente menos que las de baja competencia.

* **Calidad de Datos:** Se limpiaron y estandarizaron `X` columnas, incluyendo la conversi칩n de `yoy_change` a formato num칠rico y el renombrado de 6 columnas para facilitar el an치lisis SQL.
